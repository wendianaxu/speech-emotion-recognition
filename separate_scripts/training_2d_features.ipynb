{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wendianaxu/speech-emotion-recognition/blob/main/training_2d_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwhgQXLPc-S1"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gLHkEMSf-za",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53359f4e-b477-47bc-e237-0f3238d699d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ3NhGjceXB4",
        "outputId": "cdda8c12-844f-4930-d202-d2d39c34c636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'speech-emotion-recognition'...\n",
            "remote: Enumerating objects: 1525, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 1525 (delta 22), reused 31 (delta 9), pack-reused 1469\u001b[K\n",
            "Receiving objects: 100% (1525/1525), 213.92 MiB | 16.28 MiB/s, done.\n",
            "Resolving deltas: 100% (261/261), done.\n",
            "Updating files: 100% (1445/1445), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/wendianaxu/speech-emotion-recognition.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy directory to drive\n",
        "!cp -r \"/content/speech-emotion-recognition\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "XWYcc00n2QMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GNAcBeb1eV-U"
      },
      "outputs": [],
      "source": [
        "# test: load an audio file, extract mfccs, and visualize\n",
        "\n",
        "test_file = \"/content/drive/MyDrive/speech-emotion-recognition/RAVDESS_data/Actor_01/03-01-01-01-01-02-01.wav\"\n",
        "n_mfcc = 30\n",
        "sr = 22050 # sampling rate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize mfccs\n",
        "audio, sampling_rate = librosa.load(test_file, sr=sr, duration=None)\n",
        "test_mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "librosa.display.specshow(test_mfccs, \n",
        "                         x_axis=\"time\", \n",
        "                         sr=sr)\n",
        "plt.colorbar(format=\"%+2.f\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "swMzgoDxqFIk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "bd907679-8946-435f-9277-c510d3ad1d2c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "aRo0EShAwUTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0fc205-5cf5-498a-8228-906fe26f5aa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 53)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# function for loading an audio file\n",
        "data_path = \"/content/drive/MyDrive/speech-emotion-recognition/RAVDESS_data/\"\n",
        "def load_file(path):\n",
        "  '''\n",
        "  Load one audio file and return a 1D array containing its mfccs averaged across time\n",
        "  '''\n",
        "  audio, sampling_rate = librosa.load(path, sr=sr, duration=None)\n",
        "  # trim out silent moments from the audio\n",
        "  audio, index = librosa.effects.trim(audio, top_db=20, frame_length=512, hop_length=512)\n",
        "  mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc) # extract MFCC matrix (cols = coefficients, rows = time)\n",
        "\n",
        "  # unify sizes\n",
        "\n",
        "  return mfccs\n",
        "\n",
        "load_file(test_file).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "12Sp_TsXp52s"
      },
      "outputs": [],
      "source": [
        "# find out the max time length of trimmed audio files\n",
        "def find_max_len(path):\n",
        "  max_len = 0 # max duration of trimmed data\n",
        "  for folder in os.listdir(path): # each folder = one actor\n",
        "      for file in os.listdir(os.path.join(path, folder)):\n",
        "          if file.endswith('.wav'):\n",
        "              file_path = os.path.join(path, folder, file)\n",
        "              features = load_file(file_path)\n",
        "              features_len = features.shape[1]\n",
        "              if max_len < features_len:\n",
        "                max_len = features_len\n",
        "  return max_len"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = find_max_len(data_path)\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEwQeZc5Pynq",
        "outputId": "14a92610-8198-40c7-b2b1-68e38ba6ad99"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "144"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# redefine load_file() so that all feature matrices have the size (n_mfccs, max_len)\n",
        "def load_file(path):\n",
        "  '''\n",
        "  Load one audio file and return a 1D array containing its mfccs averaged across time\n",
        "  '''\n",
        "  audio, sampling_rate = librosa.load(path, sr=sr, duration=None)\n",
        "  # trim out silent moments from the audio\n",
        "  audio, index = librosa.effects.trim(audio, top_db=20, frame_length=512, hop_length=512)\n",
        "  mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc) # extract MFCC matrix (cols = coefficients, rows = time)\n",
        "\n",
        "  # unify sizes\n",
        "  if max_len > mfccs.shape[1]: # pad matrices that are shorter than max_len\n",
        "    pad_width = max_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "\n",
        "  return mfccs"
      ],
      "metadata": {
        "id": "AClYuCbWSh7a"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(path):\n",
        "  '''\n",
        "  Preprocess data in all folders within the dataset. \n",
        "  '''\n",
        "  X = []\n",
        "  y = []\n",
        "  for folder in os.listdir(path): # each folder = one actor\n",
        "      for file in os.listdir(os.path.join(path, folder)):\n",
        "          if file.endswith('.wav'):\n",
        "              emotion = file.split('-')[2] # get emotion label\n",
        "              if int(emotion) == 1:\n",
        "                  label = 'Neutral'\n",
        "              elif int(emotion) == 2:\n",
        "                  label = 'Calm'\n",
        "              elif int(emotion) == 3:\n",
        "                  label = 'Happy'\n",
        "              elif int(emotion) == 4:\n",
        "                  label = 'Sad'\n",
        "              elif int(emotion) == 5:\n",
        "                  label = 'Angry'\n",
        "              elif int(emotion) == 6:\n",
        "                  label = 'Fearful'\n",
        "              elif int(emotion) == 7:\n",
        "                  label = 'Disgust'\n",
        "              elif int(emotion) == 8:\n",
        "                  label = 'Surprised'\n",
        "              else:\n",
        "                  label = 'UNK'\n",
        "                  \n",
        "              file_path = os.path.join(path, folder, file)\n",
        "              features = load_file(file_path)\n",
        "              X.append(features)\n",
        "              y.append(label)\n",
        "  return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "iWSrVZ_cRiju"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "FU1ANDxI0dvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42229d0f-693e-410c-af1b-9f2695f3cb45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (1440, 30, 144)\n",
            "Shape of y: (1440,)\n"
          ]
        }
      ],
      "source": [
        "X, y = preprocess_data(data_path)\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "OHE = OneHotEncoder()\n",
        "\n",
        "y = np.array(y).reshape(-1,1)\n",
        "y = OHE.fit_transform(y).toarray()"
      ],
      "metadata": {
        "id": "IV2uPPlZ8GCK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save X, y\n",
        "np.save('/content/drive/MyDrive/speech-emotion-recognition/X_2d.npy', X)\n",
        "np.save('/content/drive/MyDrive/speech-emotion-recognition/y.npy', y)"
      ],
      "metadata": {
        "id": "yOt4ie_7u1ZZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load X, y\n",
        "X = np.load('/content/drive/MyDrive/speech-emotion-recognition/X_2d.npy')\n",
        "y = np.load('/content/drive/MyDrive/speech-emotion-recognition/y.npy')\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "bTFdRKqmvRBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d088cf-6288-4f16-901e-d6ac7e3cedf5"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1440, 30, 144) (1440, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "qoEI7uQMZu-6"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN with torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "AqbfO9HWA0Z7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform preprocessed data to Dataset class\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import Tensor\n",
        "\n",
        "# transform arrays to torch tensors\n",
        "X_train = Tensor(X_train).unsqueeze(1) # add channel = 1\n",
        "y_train = Tensor(y_train)\n",
        "X_test = Tensor(X_test).unsqueeze(1) # add channel = 1\n",
        "y_test = Tensor(y_test)\n",
        "\n",
        "train_set = TensorDataset(X_train, y_train) \n",
        "test_set = TensorDataset(X_test, y_test) \n"
      ],
      "metadata": {
        "id": "-hBDtuYDz0Ta"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GonHPEnPfedB",
        "outputId": "dd8eb44f-b95a-44cd-ac58-830e9cc033de"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1152, 1, 30, 144])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create DataLoaders\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size = batch_size, \n",
        "                          shuffle = True, num_workers = 2)\n",
        "test_loader = DataLoader(test_set, batch_size = batch_size, \n",
        "                          shuffle = True, num_workers = 2)"
      ],
      "metadata": {
        "id": "6YK4WevZAy08"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = next(iter(train_loader))\n",
        "print(X.shape, y.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaoodRZGUEUg",
        "outputId": "1a6a5770-18fd-4c7d-97c4-e97ab18d3e79"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1, 30, 144]) torch.Size([16, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "import torch.optim as optim\n",
        "\n",
        "def train(model, k_epochs = 1, print_every = 20):\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss() \n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for epoch in range(k_epochs): \n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "            # extract a batch of training data from the data loader\n",
        "            X, y = data\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # zero out gradients: we're going to recompute them in a moment\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # compute the loss (forward pass)\n",
        "            y_hat = model(X)\n",
        "            loss = loss_fn(y_hat, y)\n",
        "\n",
        "            # compute the gradient (backward pass)\n",
        "            loss.backward()\n",
        "\n",
        "            # Adam uses the gradient to update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # for printing accuracy\n",
        "            total += y.size(0)\n",
        "            correct += (torch.argmax(y_hat, dim=1) == torch.argmax(y, dim=1)).sum().item()\n",
        "\n",
        "            # print the epoch, number of batches processed, and running loss \n",
        "            # in regular intervals\n",
        "            if i % print_every == print_every - 1:    \n",
        "              print(f'[epoch: {epoch + 1}, batches: {i + 1:5d}], loss: {running_loss / print_every:.3f}, accuracy:{correct/total:.3f}')\n",
        "              running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "\n"
      ],
      "metadata": {
        "id": "9fiaCcRzom_K"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing loop\n",
        "def test(model, data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # torch.no_grad creates an environment in which we do NOT store the \n",
        "    # computational graph. We don't need to do this because we don't care about \n",
        "    # gradients unless we're training\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            X, y = data\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            \n",
        "            # run all the images through the model\n",
        "            y_hat = model(X)\n",
        "\n",
        "            # the class with the largest model output is the prediction\n",
        "            predicted = torch.argmax(y_hat, dim=1)\n",
        "\n",
        "            # compute the accuracy\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == torch.argmax(y, dim=1)).sum().item()\n",
        "\n",
        "    print(f'Test accuracy: {100 * correct // total} %')\n"
      ],
      "metadata": {
        "id": "dk-tVRp4kpYj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model1\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 128, kernel_size=3)\n",
        "    self.bn1 = nn.BatchNorm2d(128)\n",
        "    self.conv2 = nn.Conv2d(128, 64, kernel_size=3)\n",
        "    self.bn2 = nn.BatchNorm2d(64)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(64 * 204, 32)\n",
        "    self.fc2 = nn.Linear(32, 8)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "    x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model1 = ConvNet().to(device)"
      ],
      "metadata": {
        "id": "8IJkyGBWPpFP"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model1\n",
        "train(model1, k_epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqDUrRPKvPvl",
        "outputId": "7cd4e91e-7382-4312-a7d1-a42d0a0d41d7"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch: 1, batches:    20], loss: 2.376, accuracy:0.122\n",
            "[epoch: 1, batches:    40], loss: 2.060, accuracy:0.127\n",
            "[epoch: 1, batches:    60], loss: 2.063, accuracy:0.133\n",
            "[epoch: 2, batches:    20], loss: 2.041, accuracy:0.150\n",
            "[epoch: 2, batches:    40], loss: 2.035, accuracy:0.150\n",
            "[epoch: 2, batches:    60], loss: 2.025, accuracy:0.148\n",
            "[epoch: 3, batches:    20], loss: 1.922, accuracy:0.144\n",
            "[epoch: 3, batches:    40], loss: 1.899, accuracy:0.148\n",
            "[epoch: 3, batches:    60], loss: 1.877, accuracy:0.153\n",
            "[epoch: 4, batches:    20], loss: 1.775, accuracy:0.164\n",
            "[epoch: 4, batches:    40], loss: 1.854, accuracy:0.167\n",
            "[epoch: 4, batches:    60], loss: 1.800, accuracy:0.173\n",
            "[epoch: 5, batches:    20], loss: 1.683, accuracy:0.184\n",
            "[epoch: 5, batches:    40], loss: 1.676, accuracy:0.192\n",
            "[epoch: 5, batches:    60], loss: 1.686, accuracy:0.201\n",
            "[epoch: 6, batches:    20], loss: 1.541, accuracy:0.218\n",
            "[epoch: 6, batches:    40], loss: 1.530, accuracy:0.226\n",
            "[epoch: 6, batches:    60], loss: 1.530, accuracy:0.235\n",
            "[epoch: 7, batches:    20], loss: 1.398, accuracy:0.249\n",
            "[epoch: 7, batches:    40], loss: 1.424, accuracy:0.258\n",
            "[epoch: 7, batches:    60], loss: 1.410, accuracy:0.263\n",
            "[epoch: 8, batches:    20], loss: 1.287, accuracy:0.279\n",
            "[epoch: 8, batches:    40], loss: 1.289, accuracy:0.286\n",
            "[epoch: 8, batches:    60], loss: 1.249, accuracy:0.294\n",
            "[epoch: 9, batches:    20], loss: 1.234, accuracy:0.306\n",
            "[epoch: 9, batches:    40], loss: 1.090, accuracy:0.315\n",
            "[epoch: 9, batches:    60], loss: 1.190, accuracy:0.322\n",
            "[epoch: 10, batches:    20], loss: 0.990, accuracy:0.335\n",
            "[epoch: 10, batches:    40], loss: 1.049, accuracy:0.342\n",
            "[epoch: 10, batches:    60], loss: 1.038, accuracy:0.349\n",
            "[epoch: 11, batches:    20], loss: 0.938, accuracy:0.362\n",
            "[epoch: 11, batches:    40], loss: 0.957, accuracy:0.370\n",
            "[epoch: 11, batches:    60], loss: 0.869, accuracy:0.377\n",
            "[epoch: 12, batches:    20], loss: 0.833, accuracy:0.389\n",
            "[epoch: 12, batches:    40], loss: 0.775, accuracy:0.397\n",
            "[epoch: 12, batches:    60], loss: 0.890, accuracy:0.403\n",
            "[epoch: 13, batches:    20], loss: 0.693, accuracy:0.414\n",
            "[epoch: 13, batches:    40], loss: 0.722, accuracy:0.422\n",
            "[epoch: 13, batches:    60], loss: 0.781, accuracy:0.428\n",
            "[epoch: 14, batches:    20], loss: 0.717, accuracy:0.439\n",
            "[epoch: 14, batches:    40], loss: 0.745, accuracy:0.444\n",
            "[epoch: 14, batches:    60], loss: 0.653, accuracy:0.451\n",
            "[epoch: 15, batches:    20], loss: 0.535, accuracy:0.460\n",
            "[epoch: 15, batches:    40], loss: 0.648, accuracy:0.466\n",
            "[epoch: 15, batches:    60], loss: 0.646, accuracy:0.472\n",
            "[epoch: 16, batches:    20], loss: 0.643, accuracy:0.480\n",
            "[epoch: 16, batches:    40], loss: 0.585, accuracy:0.485\n",
            "[epoch: 16, batches:    60], loss: 0.554, accuracy:0.491\n",
            "[epoch: 17, batches:    20], loss: 0.560, accuracy:0.499\n",
            "[epoch: 17, batches:    40], loss: 0.612, accuracy:0.503\n",
            "[epoch: 17, batches:    60], loss: 0.499, accuracy:0.508\n",
            "[epoch: 18, batches:    20], loss: 0.445, accuracy:0.517\n",
            "[epoch: 18, batches:    40], loss: 0.397, accuracy:0.522\n",
            "[epoch: 18, batches:    60], loss: 0.531, accuracy:0.527\n",
            "[epoch: 19, batches:    20], loss: 0.409, accuracy:0.534\n",
            "[epoch: 19, batches:    40], loss: 0.430, accuracy:0.539\n",
            "[epoch: 19, batches:    60], loss: 0.409, accuracy:0.544\n",
            "[epoch: 20, batches:    20], loss: 0.317, accuracy:0.551\n",
            "[epoch: 20, batches:    40], loss: 0.305, accuracy:0.557\n",
            "[epoch: 20, batches:    60], loss: 0.368, accuracy:0.561\n",
            "[epoch: 21, batches:    20], loss: 0.258, accuracy:0.568\n",
            "[epoch: 21, batches:    40], loss: 0.284, accuracy:0.573\n",
            "[epoch: 21, batches:    60], loss: 0.394, accuracy:0.576\n",
            "[epoch: 22, batches:    20], loss: 0.304, accuracy:0.583\n",
            "[epoch: 22, batches:    40], loss: 0.320, accuracy:0.587\n",
            "[epoch: 22, batches:    60], loss: 0.341, accuracy:0.590\n",
            "[epoch: 23, batches:    20], loss: 0.254, accuracy:0.597\n",
            "[epoch: 23, batches:    40], loss: 0.261, accuracy:0.601\n",
            "[epoch: 23, batches:    60], loss: 0.244, accuracy:0.604\n",
            "[epoch: 24, batches:    20], loss: 0.239, accuracy:0.610\n",
            "[epoch: 24, batches:    40], loss: 0.277, accuracy:0.613\n",
            "[epoch: 24, batches:    60], loss: 0.222, accuracy:0.617\n",
            "[epoch: 25, batches:    20], loss: 0.135, accuracy:0.623\n",
            "[epoch: 25, batches:    40], loss: 0.195, accuracy:0.627\n",
            "[epoch: 25, batches:    60], loss: 0.233, accuracy:0.630\n",
            "[epoch: 26, batches:    20], loss: 0.169, accuracy:0.635\n",
            "[epoch: 26, batches:    40], loss: 0.187, accuracy:0.638\n",
            "[epoch: 26, batches:    60], loss: 0.167, accuracy:0.642\n",
            "[epoch: 27, batches:    20], loss: 0.171, accuracy:0.647\n",
            "[epoch: 27, batches:    40], loss: 0.133, accuracy:0.650\n",
            "[epoch: 27, batches:    60], loss: 0.143, accuracy:0.653\n",
            "[epoch: 28, batches:    20], loss: 0.165, accuracy:0.657\n",
            "[epoch: 28, batches:    40], loss: 0.167, accuracy:0.660\n",
            "[epoch: 28, batches:    60], loss: 0.174, accuracy:0.663\n",
            "[epoch: 29, batches:    20], loss: 0.144, accuracy:0.668\n",
            "[epoch: 29, batches:    40], loss: 0.157, accuracy:0.670\n",
            "[epoch: 29, batches:    60], loss: 0.127, accuracy:0.673\n",
            "[epoch: 30, batches:    20], loss: 0.111, accuracy:0.677\n",
            "[epoch: 30, batches:    40], loss: 0.124, accuracy:0.680\n",
            "[epoch: 30, batches:    60], loss: 0.106, accuracy:0.683\n",
            "[epoch: 31, batches:    20], loss: 0.120, accuracy:0.687\n",
            "[epoch: 31, batches:    40], loss: 0.148, accuracy:0.689\n",
            "[epoch: 31, batches:    60], loss: 0.153, accuracy:0.691\n",
            "[epoch: 32, batches:    20], loss: 0.169, accuracy:0.694\n",
            "[epoch: 32, batches:    40], loss: 0.168, accuracy:0.697\n",
            "[epoch: 32, batches:    60], loss: 0.202, accuracy:0.699\n",
            "[epoch: 33, batches:    20], loss: 0.162, accuracy:0.702\n",
            "[epoch: 33, batches:    40], loss: 0.145, accuracy:0.704\n",
            "[epoch: 33, batches:    60], loss: 0.146, accuracy:0.706\n",
            "[epoch: 34, batches:    20], loss: 0.120, accuracy:0.709\n",
            "[epoch: 34, batches:    40], loss: 0.099, accuracy:0.711\n",
            "[epoch: 34, batches:    60], loss: 0.118, accuracy:0.713\n",
            "[epoch: 35, batches:    20], loss: 0.088, accuracy:0.717\n",
            "[epoch: 35, batches:    40], loss: 0.102, accuracy:0.719\n",
            "[epoch: 35, batches:    60], loss: 0.115, accuracy:0.721\n",
            "[epoch: 36, batches:    20], loss: 0.088, accuracy:0.724\n",
            "[epoch: 36, batches:    40], loss: 0.055, accuracy:0.726\n",
            "[epoch: 36, batches:    60], loss: 0.097, accuracy:0.728\n",
            "[epoch: 37, batches:    20], loss: 0.072, accuracy:0.731\n",
            "[epoch: 37, batches:    40], loss: 0.052, accuracy:0.733\n",
            "[epoch: 37, batches:    60], loss: 0.066, accuracy:0.735\n",
            "[epoch: 38, batches:    20], loss: 0.054, accuracy:0.738\n",
            "[epoch: 38, batches:    40], loss: 0.035, accuracy:0.740\n",
            "[epoch: 38, batches:    60], loss: 0.067, accuracy:0.742\n",
            "[epoch: 39, batches:    20], loss: 0.058, accuracy:0.745\n",
            "[epoch: 39, batches:    40], loss: 0.169, accuracy:0.746\n",
            "[epoch: 39, batches:    60], loss: 0.194, accuracy:0.747\n",
            "[epoch: 40, batches:    20], loss: 0.212, accuracy:0.749\n",
            "[epoch: 40, batches:    40], loss: 0.144, accuracy:0.751\n",
            "[epoch: 40, batches:    60], loss: 0.258, accuracy:0.752\n",
            "[epoch: 41, batches:    20], loss: 0.146, accuracy:0.754\n",
            "[epoch: 41, batches:    40], loss: 0.166, accuracy:0.755\n",
            "[epoch: 41, batches:    60], loss: 0.155, accuracy:0.756\n",
            "[epoch: 42, batches:    20], loss: 0.108, accuracy:0.759\n",
            "[epoch: 42, batches:    40], loss: 0.061, accuracy:0.760\n",
            "[epoch: 42, batches:    60], loss: 0.048, accuracy:0.762\n",
            "[epoch: 43, batches:    20], loss: 0.040, accuracy:0.764\n",
            "[epoch: 43, batches:    40], loss: 0.056, accuracy:0.766\n",
            "[epoch: 43, batches:    60], loss: 0.053, accuracy:0.767\n",
            "[epoch: 44, batches:    20], loss: 0.054, accuracy:0.769\n",
            "[epoch: 44, batches:    40], loss: 0.045, accuracy:0.771\n",
            "[epoch: 44, batches:    60], loss: 0.046, accuracy:0.772\n",
            "[epoch: 45, batches:    20], loss: 0.026, accuracy:0.774\n",
            "[epoch: 45, batches:    40], loss: 0.034, accuracy:0.776\n",
            "[epoch: 45, batches:    60], loss: 0.022, accuracy:0.777\n",
            "[epoch: 46, batches:    20], loss: 0.018, accuracy:0.779\n",
            "[epoch: 46, batches:    40], loss: 0.030, accuracy:0.780\n",
            "[epoch: 46, batches:    60], loss: 0.012, accuracy:0.782\n",
            "[epoch: 47, batches:    20], loss: 0.024, accuracy:0.784\n",
            "[epoch: 47, batches:    40], loss: 0.016, accuracy:0.785\n",
            "[epoch: 47, batches:    60], loss: 0.008, accuracy:0.786\n",
            "[epoch: 48, batches:    20], loss: 0.005, accuracy:0.788\n",
            "[epoch: 48, batches:    40], loss: 0.016, accuracy:0.790\n",
            "[epoch: 48, batches:    60], loss: 0.026, accuracy:0.791\n",
            "[epoch: 49, batches:    20], loss: 0.017, accuracy:0.793\n",
            "[epoch: 49, batches:    40], loss: 0.013, accuracy:0.794\n",
            "[epoch: 49, batches:    60], loss: 0.009, accuracy:0.795\n",
            "[epoch: 50, batches:    20], loss: 0.018, accuracy:0.797\n",
            "[epoch: 50, batches:    40], loss: 0.010, accuracy:0.798\n",
            "[epoch: 50, batches:    60], loss: 0.012, accuracy:0.799\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test model1\n",
        "test(model1, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRsArYBMvjMJ",
        "outputId": "e3eedbca-ff79-4670-fa56-9d27ac73af9e"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 54 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model2: with dropout\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, dropout_prob = 0.5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 128, kernel_size=3)\n",
        "    self.bn1 = nn.BatchNorm2d(128)\n",
        "    self.conv2 = nn.Conv2d(128, 64, kernel_size=3)\n",
        "    self.bn2 = nn.BatchNorm2d(64)\n",
        "    self.dropout = nn.Dropout(dropout_prob)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(64 * 204, 32)\n",
        "    self.fc2 = nn.Linear(32, 8)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "    x = self.dropout(x)\n",
        "    x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "    x = self.dropout(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model2 = ConvNet().to(device)"
      ],
      "metadata": {
        "id": "m_VVL_dRtvWI"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model2, k_epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJIG2Yzrv6oO",
        "outputId": "d3f841cd-7726-4301-9388-49ebf89c97dd"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch: 1, batches:    20], loss: 2.076, accuracy:0.191\n",
            "[epoch: 1, batches:    40], loss: 1.993, accuracy:0.222\n",
            "[epoch: 1, batches:    60], loss: 1.917, accuracy:0.240\n",
            "[epoch: 2, batches:    20], loss: 1.769, accuracy:0.262\n",
            "[epoch: 2, batches:    40], loss: 1.675, accuracy:0.279\n",
            "[epoch: 2, batches:    60], loss: 1.774, accuracy:0.283\n",
            "[epoch: 3, batches:    20], loss: 1.596, accuracy:0.303\n",
            "[epoch: 3, batches:    40], loss: 1.556, accuracy:0.316\n",
            "[epoch: 3, batches:    60], loss: 1.570, accuracy:0.324\n",
            "[epoch: 4, batches:    20], loss: 1.418, accuracy:0.348\n",
            "[epoch: 4, batches:    40], loss: 1.366, accuracy:0.356\n",
            "[epoch: 4, batches:    60], loss: 1.479, accuracy:0.362\n",
            "[epoch: 5, batches:    20], loss: 1.360, accuracy:0.374\n",
            "[epoch: 5, batches:    40], loss: 1.359, accuracy:0.382\n",
            "[epoch: 5, batches:    60], loss: 1.317, accuracy:0.388\n",
            "[epoch: 6, batches:    20], loss: 1.154, accuracy:0.402\n",
            "[epoch: 6, batches:    40], loss: 1.314, accuracy:0.407\n",
            "[epoch: 6, batches:    60], loss: 1.179, accuracy:0.414\n",
            "[epoch: 7, batches:    20], loss: 1.222, accuracy:0.424\n",
            "[epoch: 7, batches:    40], loss: 1.161, accuracy:0.429\n",
            "[epoch: 7, batches:    60], loss: 1.166, accuracy:0.434\n",
            "[epoch: 8, batches:    20], loss: 1.006, accuracy:0.445\n",
            "[epoch: 8, batches:    40], loss: 1.115, accuracy:0.452\n",
            "[epoch: 8, batches:    60], loss: 1.065, accuracy:0.456\n",
            "[epoch: 9, batches:    20], loss: 0.987, accuracy:0.465\n",
            "[epoch: 9, batches:    40], loss: 0.920, accuracy:0.473\n",
            "[epoch: 9, batches:    60], loss: 0.956, accuracy:0.477\n",
            "[epoch: 10, batches:    20], loss: 0.846, accuracy:0.487\n",
            "[epoch: 10, batches:    40], loss: 0.920, accuracy:0.491\n",
            "[epoch: 10, batches:    60], loss: 1.115, accuracy:0.493\n",
            "[epoch: 11, batches:    20], loss: 0.962, accuracy:0.499\n",
            "[epoch: 11, batches:    40], loss: 0.876, accuracy:0.503\n",
            "[epoch: 11, batches:    60], loss: 0.937, accuracy:0.506\n",
            "[epoch: 12, batches:    20], loss: 0.829, accuracy:0.512\n",
            "[epoch: 12, batches:    40], loss: 0.785, accuracy:0.518\n",
            "[epoch: 12, batches:    60], loss: 0.781, accuracy:0.522\n",
            "[epoch: 13, batches:    20], loss: 0.761, accuracy:0.529\n",
            "[epoch: 13, batches:    40], loss: 0.749, accuracy:0.534\n",
            "[epoch: 13, batches:    60], loss: 0.851, accuracy:0.537\n",
            "[epoch: 14, batches:    20], loss: 0.884, accuracy:0.541\n",
            "[epoch: 14, batches:    40], loss: 0.708, accuracy:0.546\n",
            "[epoch: 14, batches:    60], loss: 0.752, accuracy:0.549\n",
            "[epoch: 15, batches:    20], loss: 0.652, accuracy:0.555\n",
            "[epoch: 15, batches:    40], loss: 0.834, accuracy:0.558\n",
            "[epoch: 15, batches:    60], loss: 0.633, accuracy:0.562\n",
            "[epoch: 16, batches:    20], loss: 0.688, accuracy:0.568\n",
            "[epoch: 16, batches:    40], loss: 0.705, accuracy:0.570\n",
            "[epoch: 16, batches:    60], loss: 0.748, accuracy:0.573\n",
            "[epoch: 17, batches:    20], loss: 0.672, accuracy:0.577\n",
            "[epoch: 17, batches:    40], loss: 0.637, accuracy:0.581\n",
            "[epoch: 17, batches:    60], loss: 0.663, accuracy:0.583\n",
            "[epoch: 18, batches:    20], loss: 0.504, accuracy:0.589\n",
            "[epoch: 18, batches:    40], loss: 0.549, accuracy:0.593\n",
            "[epoch: 18, batches:    60], loss: 0.599, accuracy:0.596\n",
            "[epoch: 19, batches:    20], loss: 0.573, accuracy:0.600\n",
            "[epoch: 19, batches:    40], loss: 0.495, accuracy:0.604\n",
            "[epoch: 19, batches:    60], loss: 0.589, accuracy:0.606\n",
            "[epoch: 20, batches:    20], loss: 0.503, accuracy:0.610\n",
            "[epoch: 20, batches:    40], loss: 0.552, accuracy:0.613\n",
            "[epoch: 20, batches:    60], loss: 0.544, accuracy:0.615\n",
            "[epoch: 21, batches:    20], loss: 0.521, accuracy:0.619\n",
            "[epoch: 21, batches:    40], loss: 0.548, accuracy:0.622\n",
            "[epoch: 21, batches:    60], loss: 0.523, accuracy:0.624\n",
            "[epoch: 22, batches:    20], loss: 0.435, accuracy:0.628\n",
            "[epoch: 22, batches:    40], loss: 0.432, accuracy:0.631\n",
            "[epoch: 22, batches:    60], loss: 0.515, accuracy:0.634\n",
            "[epoch: 23, batches:    20], loss: 0.407, accuracy:0.637\n",
            "[epoch: 23, batches:    40], loss: 0.488, accuracy:0.639\n",
            "[epoch: 23, batches:    60], loss: 0.430, accuracy:0.642\n",
            "[epoch: 24, batches:    20], loss: 0.440, accuracy:0.645\n",
            "[epoch: 24, batches:    40], loss: 0.440, accuracy:0.647\n",
            "[epoch: 24, batches:    60], loss: 0.492, accuracy:0.649\n",
            "[epoch: 25, batches:    20], loss: 0.516, accuracy:0.652\n",
            "[epoch: 25, batches:    40], loss: 0.388, accuracy:0.655\n",
            "[epoch: 25, batches:    60], loss: 0.424, accuracy:0.657\n",
            "[epoch: 26, batches:    20], loss: 0.379, accuracy:0.660\n",
            "[epoch: 26, batches:    40], loss: 0.329, accuracy:0.663\n",
            "[epoch: 26, batches:    60], loss: 0.342, accuracy:0.665\n",
            "[epoch: 27, batches:    20], loss: 0.350, accuracy:0.668\n",
            "[epoch: 27, batches:    40], loss: 0.416, accuracy:0.670\n",
            "[epoch: 27, batches:    60], loss: 0.406, accuracy:0.672\n",
            "[epoch: 28, batches:    20], loss: 0.375, accuracy:0.675\n",
            "[epoch: 28, batches:    40], loss: 0.429, accuracy:0.677\n",
            "[epoch: 28, batches:    60], loss: 0.374, accuracy:0.678\n",
            "[epoch: 29, batches:    20], loss: 0.351, accuracy:0.681\n",
            "[epoch: 29, batches:    40], loss: 0.324, accuracy:0.683\n",
            "[epoch: 29, batches:    60], loss: 0.413, accuracy:0.685\n",
            "[epoch: 30, batches:    20], loss: 0.344, accuracy:0.687\n",
            "[epoch: 30, batches:    40], loss: 0.313, accuracy:0.689\n",
            "[epoch: 30, batches:    60], loss: 0.345, accuracy:0.691\n",
            "[epoch: 31, batches:    20], loss: 0.351, accuracy:0.694\n",
            "[epoch: 31, batches:    40], loss: 0.372, accuracy:0.695\n",
            "[epoch: 31, batches:    60], loss: 0.372, accuracy:0.697\n",
            "[epoch: 32, batches:    20], loss: 0.322, accuracy:0.699\n",
            "[epoch: 32, batches:    40], loss: 0.377, accuracy:0.701\n",
            "[epoch: 32, batches:    60], loss: 0.358, accuracy:0.702\n",
            "[epoch: 33, batches:    20], loss: 0.314, accuracy:0.705\n",
            "[epoch: 33, batches:    40], loss: 0.300, accuracy:0.706\n",
            "[epoch: 33, batches:    60], loss: 0.352, accuracy:0.708\n",
            "[epoch: 34, batches:    20], loss: 0.307, accuracy:0.710\n",
            "[epoch: 34, batches:    40], loss: 0.290, accuracy:0.712\n",
            "[epoch: 34, batches:    60], loss: 0.297, accuracy:0.713\n",
            "[epoch: 35, batches:    20], loss: 0.269, accuracy:0.716\n",
            "[epoch: 35, batches:    40], loss: 0.401, accuracy:0.717\n",
            "[epoch: 35, batches:    60], loss: 0.394, accuracy:0.718\n",
            "[epoch: 36, batches:    20], loss: 0.279, accuracy:0.720\n",
            "[epoch: 36, batches:    40], loss: 0.298, accuracy:0.721\n",
            "[epoch: 36, batches:    60], loss: 0.273, accuracy:0.722\n",
            "[epoch: 37, batches:    20], loss: 0.268, accuracy:0.725\n",
            "[epoch: 37, batches:    40], loss: 0.258, accuracy:0.726\n",
            "[epoch: 37, batches:    60], loss: 0.364, accuracy:0.727\n",
            "[epoch: 38, batches:    20], loss: 0.305, accuracy:0.729\n",
            "[epoch: 38, batches:    40], loss: 0.315, accuracy:0.730\n",
            "[epoch: 38, batches:    60], loss: 0.349, accuracy:0.731\n",
            "[epoch: 39, batches:    20], loss: 0.331, accuracy:0.733\n",
            "[epoch: 39, batches:    40], loss: 0.210, accuracy:0.734\n",
            "[epoch: 39, batches:    60], loss: 0.254, accuracy:0.735\n",
            "[epoch: 40, batches:    20], loss: 0.205, accuracy:0.738\n",
            "[epoch: 40, batches:    40], loss: 0.225, accuracy:0.739\n",
            "[epoch: 40, batches:    60], loss: 0.260, accuracy:0.740\n",
            "[epoch: 41, batches:    20], loss: 0.269, accuracy:0.742\n",
            "[epoch: 41, batches:    40], loss: 0.261, accuracy:0.743\n",
            "[epoch: 41, batches:    60], loss: 0.315, accuracy:0.744\n",
            "[epoch: 42, batches:    20], loss: 0.234, accuracy:0.746\n",
            "[epoch: 42, batches:    40], loss: 0.214, accuracy:0.747\n",
            "[epoch: 42, batches:    60], loss: 0.219, accuracy:0.748\n",
            "[epoch: 43, batches:    20], loss: 0.277, accuracy:0.750\n",
            "[epoch: 43, batches:    40], loss: 0.214, accuracy:0.751\n",
            "[epoch: 43, batches:    60], loss: 0.262, accuracy:0.752\n",
            "[epoch: 44, batches:    20], loss: 0.206, accuracy:0.754\n",
            "[epoch: 44, batches:    40], loss: 0.228, accuracy:0.755\n",
            "[epoch: 44, batches:    60], loss: 0.186, accuracy:0.756\n",
            "[epoch: 45, batches:    20], loss: 0.207, accuracy:0.758\n",
            "[epoch: 45, batches:    40], loss: 0.233, accuracy:0.759\n",
            "[epoch: 45, batches:    60], loss: 0.317, accuracy:0.759\n",
            "[epoch: 46, batches:    20], loss: 0.277, accuracy:0.761\n",
            "[epoch: 46, batches:    40], loss: 0.210, accuracy:0.762\n",
            "[epoch: 46, batches:    60], loss: 0.227, accuracy:0.763\n",
            "[epoch: 47, batches:    20], loss: 0.210, accuracy:0.764\n",
            "[epoch: 47, batches:    40], loss: 0.192, accuracy:0.765\n",
            "[epoch: 47, batches:    60], loss: 0.188, accuracy:0.766\n",
            "[epoch: 48, batches:    20], loss: 0.194, accuracy:0.768\n",
            "[epoch: 48, batches:    40], loss: 0.179, accuracy:0.769\n",
            "[epoch: 48, batches:    60], loss: 0.167, accuracy:0.770\n",
            "[epoch: 49, batches:    20], loss: 0.190, accuracy:0.771\n",
            "[epoch: 49, batches:    40], loss: 0.160, accuracy:0.772\n",
            "[epoch: 49, batches:    60], loss: 0.171, accuracy:0.773\n",
            "[epoch: 50, batches:    20], loss: 0.196, accuracy:0.775\n",
            "[epoch: 50, batches:    40], loss: 0.210, accuracy:0.775\n",
            "[epoch: 50, batches:    60], loss: 0.203, accuracy:0.776\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model2, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCwKhDMxwIHr",
        "outputId": "68b01700-4140-47fc-968a-2219b0d52131"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 54 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model3\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, dropout_prob = 0.5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 64, kernel_size=3)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.conv2 = nn.Conv2d(64, 32, kernel_size=3)\n",
        "    self.bn2 = nn.BatchNorm2d(32)\n",
        "    self.dropout = nn.Dropout(dropout_prob)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(64 * 102, 128)\n",
        "    self.fc2 = nn.Linear(128, 8)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "    x = self.dropout(x)\n",
        "    x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "    x = self.dropout(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model3 = ConvNet().to(device)"
      ],
      "metadata": {
        "id": "XwquVMu_cmwE"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model3, k_epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBE3q-63dDPM",
        "outputId": "1d6403b1-8542-472c-e814-673eb1e44072"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch: 1, batches:    20], loss: 2.280, accuracy:0.153\n",
            "[epoch: 1, batches:    40], loss: 1.945, accuracy:0.188\n",
            "[epoch: 1, batches:    60], loss: 1.820, accuracy:0.212\n",
            "[epoch: 2, batches:    20], loss: 1.768, accuracy:0.237\n",
            "[epoch: 2, batches:    40], loss: 1.650, accuracy:0.258\n",
            "[epoch: 2, batches:    60], loss: 1.704, accuracy:0.268\n",
            "[epoch: 3, batches:    20], loss: 1.577, accuracy:0.291\n",
            "[epoch: 3, batches:    40], loss: 1.526, accuracy:0.300\n",
            "[epoch: 3, batches:    60], loss: 1.562, accuracy:0.311\n",
            "[epoch: 4, batches:    20], loss: 1.433, accuracy:0.327\n",
            "[epoch: 4, batches:    40], loss: 1.513, accuracy:0.336\n",
            "[epoch: 4, batches:    60], loss: 1.380, accuracy:0.344\n",
            "[epoch: 5, batches:    20], loss: 1.399, accuracy:0.355\n",
            "[epoch: 5, batches:    40], loss: 1.369, accuracy:0.363\n",
            "[epoch: 5, batches:    60], loss: 1.271, accuracy:0.372\n",
            "[epoch: 6, batches:    20], loss: 1.269, accuracy:0.386\n",
            "[epoch: 6, batches:    40], loss: 1.183, accuracy:0.393\n",
            "[epoch: 6, batches:    60], loss: 1.266, accuracy:0.400\n",
            "[epoch: 7, batches:    20], loss: 1.088, accuracy:0.414\n",
            "[epoch: 7, batches:    40], loss: 1.206, accuracy:0.421\n",
            "[epoch: 7, batches:    60], loss: 1.201, accuracy:0.427\n",
            "[epoch: 8, batches:    20], loss: 1.011, accuracy:0.436\n",
            "[epoch: 8, batches:    40], loss: 1.140, accuracy:0.441\n",
            "[epoch: 8, batches:    60], loss: 1.134, accuracy:0.446\n",
            "[epoch: 9, batches:    20], loss: 1.045, accuracy:0.456\n",
            "[epoch: 9, batches:    40], loss: 0.942, accuracy:0.463\n",
            "[epoch: 9, batches:    60], loss: 0.910, accuracy:0.470\n",
            "[epoch: 10, batches:    20], loss: 1.006, accuracy:0.475\n",
            "[epoch: 10, batches:    40], loss: 0.915, accuracy:0.479\n",
            "[epoch: 10, batches:    60], loss: 0.924, accuracy:0.484\n",
            "[epoch: 11, batches:    20], loss: 0.841, accuracy:0.492\n",
            "[epoch: 11, batches:    40], loss: 0.970, accuracy:0.496\n",
            "[epoch: 11, batches:    60], loss: 0.837, accuracy:0.501\n",
            "[epoch: 12, batches:    20], loss: 0.873, accuracy:0.508\n",
            "[epoch: 12, batches:    40], loss: 0.717, accuracy:0.514\n",
            "[epoch: 12, batches:    60], loss: 0.737, accuracy:0.519\n",
            "[epoch: 13, batches:    20], loss: 0.759, accuracy:0.526\n",
            "[epoch: 13, batches:    40], loss: 0.761, accuracy:0.529\n",
            "[epoch: 13, batches:    60], loss: 0.773, accuracy:0.533\n",
            "[epoch: 14, batches:    20], loss: 0.687, accuracy:0.540\n",
            "[epoch: 14, batches:    40], loss: 0.715, accuracy:0.544\n",
            "[epoch: 14, batches:    60], loss: 0.713, accuracy:0.548\n",
            "[epoch: 15, batches:    20], loss: 0.618, accuracy:0.554\n",
            "[epoch: 15, batches:    40], loss: 0.604, accuracy:0.558\n",
            "[epoch: 15, batches:    60], loss: 0.708, accuracy:0.561\n",
            "[epoch: 16, batches:    20], loss: 0.655, accuracy:0.567\n",
            "[epoch: 16, batches:    40], loss: 0.564, accuracy:0.571\n",
            "[epoch: 16, batches:    60], loss: 0.582, accuracy:0.575\n",
            "[epoch: 17, batches:    20], loss: 0.512, accuracy:0.580\n",
            "[epoch: 17, batches:    40], loss: 0.588, accuracy:0.584\n",
            "[epoch: 17, batches:    60], loss: 0.551, accuracy:0.588\n",
            "[epoch: 18, batches:    20], loss: 0.449, accuracy:0.594\n",
            "[epoch: 18, batches:    40], loss: 0.512, accuracy:0.598\n",
            "[epoch: 18, batches:    60], loss: 0.487, accuracy:0.602\n",
            "[epoch: 19, batches:    20], loss: 0.505, accuracy:0.607\n",
            "[epoch: 19, batches:    40], loss: 0.444, accuracy:0.610\n",
            "[epoch: 19, batches:    60], loss: 0.736, accuracy:0.612\n",
            "[epoch: 20, batches:    20], loss: 0.522, accuracy:0.616\n",
            "[epoch: 20, batches:    40], loss: 0.458, accuracy:0.619\n",
            "[epoch: 20, batches:    60], loss: 0.455, accuracy:0.623\n",
            "[epoch: 21, batches:    20], loss: 0.397, accuracy:0.628\n",
            "[epoch: 21, batches:    40], loss: 0.482, accuracy:0.630\n",
            "[epoch: 21, batches:    60], loss: 0.412, accuracy:0.633\n",
            "[epoch: 22, batches:    20], loss: 0.323, accuracy:0.638\n",
            "[epoch: 22, batches:    40], loss: 0.412, accuracy:0.641\n",
            "[epoch: 22, batches:    60], loss: 0.338, accuracy:0.644\n",
            "[epoch: 23, batches:    20], loss: 0.304, accuracy:0.648\n",
            "[epoch: 23, batches:    40], loss: 0.335, accuracy:0.651\n",
            "[epoch: 23, batches:    60], loss: 0.446, accuracy:0.653\n",
            "[epoch: 24, batches:    20], loss: 0.347, accuracy:0.657\n",
            "[epoch: 24, batches:    40], loss: 0.357, accuracy:0.660\n",
            "[epoch: 24, batches:    60], loss: 0.420, accuracy:0.662\n",
            "[epoch: 25, batches:    20], loss: 0.344, accuracy:0.665\n",
            "[epoch: 25, batches:    40], loss: 0.325, accuracy:0.668\n",
            "[epoch: 25, batches:    60], loss: 0.313, accuracy:0.670\n",
            "[epoch: 26, batches:    20], loss: 0.320, accuracy:0.674\n",
            "[epoch: 26, batches:    40], loss: 0.371, accuracy:0.676\n",
            "[epoch: 26, batches:    60], loss: 0.338, accuracy:0.678\n",
            "[epoch: 27, batches:    20], loss: 0.293, accuracy:0.682\n",
            "[epoch: 27, batches:    40], loss: 0.242, accuracy:0.684\n",
            "[epoch: 27, batches:    60], loss: 0.300, accuracy:0.686\n",
            "[epoch: 28, batches:    20], loss: 0.251, accuracy:0.690\n",
            "[epoch: 28, batches:    40], loss: 0.285, accuracy:0.692\n",
            "[epoch: 28, batches:    60], loss: 0.419, accuracy:0.694\n",
            "[epoch: 29, batches:    20], loss: 0.273, accuracy:0.697\n",
            "[epoch: 29, batches:    40], loss: 0.324, accuracy:0.699\n",
            "[epoch: 29, batches:    60], loss: 0.302, accuracy:0.700\n",
            "[epoch: 30, batches:    20], loss: 0.331, accuracy:0.703\n",
            "[epoch: 30, batches:    40], loss: 0.300, accuracy:0.705\n",
            "[epoch: 30, batches:    60], loss: 0.352, accuracy:0.707\n",
            "[epoch: 31, batches:    20], loss: 0.302, accuracy:0.709\n",
            "[epoch: 31, batches:    40], loss: 0.366, accuracy:0.711\n",
            "[epoch: 31, batches:    60], loss: 0.279, accuracy:0.712\n",
            "[epoch: 32, batches:    20], loss: 0.261, accuracy:0.715\n",
            "[epoch: 32, batches:    40], loss: 0.222, accuracy:0.717\n",
            "[epoch: 32, batches:    60], loss: 0.216, accuracy:0.719\n",
            "[epoch: 33, batches:    20], loss: 0.199, accuracy:0.722\n",
            "[epoch: 33, batches:    40], loss: 0.235, accuracy:0.724\n",
            "[epoch: 33, batches:    60], loss: 0.228, accuracy:0.725\n",
            "[epoch: 34, batches:    20], loss: 0.203, accuracy:0.728\n",
            "[epoch: 34, batches:    40], loss: 0.274, accuracy:0.730\n",
            "[epoch: 34, batches:    60], loss: 0.258, accuracy:0.731\n",
            "[epoch: 35, batches:    20], loss: 0.191, accuracy:0.734\n",
            "[epoch: 35, batches:    40], loss: 0.181, accuracy:0.736\n",
            "[epoch: 35, batches:    60], loss: 0.204, accuracy:0.737\n",
            "[epoch: 36, batches:    20], loss: 0.225, accuracy:0.740\n",
            "[epoch: 36, batches:    40], loss: 0.183, accuracy:0.741\n",
            "[epoch: 36, batches:    60], loss: 0.194, accuracy:0.743\n",
            "[epoch: 37, batches:    20], loss: 0.264, accuracy:0.745\n",
            "[epoch: 37, batches:    40], loss: 0.216, accuracy:0.746\n",
            "[epoch: 37, batches:    60], loss: 0.231, accuracy:0.747\n",
            "[epoch: 38, batches:    20], loss: 0.123, accuracy:0.750\n",
            "[epoch: 38, batches:    40], loss: 0.123, accuracy:0.752\n",
            "[epoch: 38, batches:    60], loss: 0.172, accuracy:0.753\n",
            "[epoch: 39, batches:    20], loss: 0.187, accuracy:0.755\n",
            "[epoch: 39, batches:    40], loss: 0.194, accuracy:0.756\n",
            "[epoch: 39, batches:    60], loss: 0.213, accuracy:0.758\n",
            "[epoch: 40, batches:    20], loss: 0.177, accuracy:0.760\n",
            "[epoch: 40, batches:    40], loss: 0.140, accuracy:0.761\n",
            "[epoch: 40, batches:    60], loss: 0.139, accuracy:0.762\n",
            "[epoch: 41, batches:    20], loss: 0.150, accuracy:0.764\n",
            "[epoch: 41, batches:    40], loss: 0.176, accuracy:0.766\n",
            "[epoch: 41, batches:    60], loss: 0.135, accuracy:0.767\n",
            "[epoch: 42, batches:    20], loss: 0.126, accuracy:0.769\n",
            "[epoch: 42, batches:    40], loss: 0.188, accuracy:0.770\n",
            "[epoch: 42, batches:    60], loss: 0.179, accuracy:0.772\n",
            "[epoch: 43, batches:    20], loss: 0.152, accuracy:0.773\n",
            "[epoch: 43, batches:    40], loss: 0.152, accuracy:0.774\n",
            "[epoch: 43, batches:    60], loss: 0.182, accuracy:0.776\n",
            "[epoch: 44, batches:    20], loss: 0.150, accuracy:0.777\n",
            "[epoch: 44, batches:    40], loss: 0.130, accuracy:0.779\n",
            "[epoch: 44, batches:    60], loss: 0.171, accuracy:0.780\n",
            "[epoch: 45, batches:    20], loss: 0.190, accuracy:0.781\n",
            "[epoch: 45, batches:    40], loss: 0.181, accuracy:0.782\n",
            "[epoch: 45, batches:    60], loss: 0.154, accuracy:0.783\n",
            "[epoch: 46, batches:    20], loss: 0.140, accuracy:0.785\n",
            "[epoch: 46, batches:    40], loss: 0.128, accuracy:0.786\n",
            "[epoch: 46, batches:    60], loss: 0.192, accuracy:0.787\n",
            "[epoch: 47, batches:    20], loss: 0.110, accuracy:0.788\n",
            "[epoch: 47, batches:    40], loss: 0.151, accuracy:0.789\n",
            "[epoch: 47, batches:    60], loss: 0.148, accuracy:0.790\n",
            "[epoch: 48, batches:    20], loss: 0.122, accuracy:0.792\n",
            "[epoch: 48, batches:    40], loss: 0.142, accuracy:0.793\n",
            "[epoch: 48, batches:    60], loss: 0.204, accuracy:0.794\n",
            "[epoch: 49, batches:    20], loss: 0.174, accuracy:0.795\n",
            "[epoch: 49, batches:    40], loss: 0.171, accuracy:0.796\n",
            "[epoch: 49, batches:    60], loss: 0.136, accuracy:0.797\n",
            "[epoch: 50, batches:    20], loss: 0.157, accuracy:0.798\n",
            "[epoch: 50, batches:    40], loss: 0.108, accuracy:0.799\n",
            "[epoch: 50, batches:    60], loss: 0.098, accuracy:0.800\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model3, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3TNZ4jzdGbX",
        "outputId": "85199a67-feb0-4502-f98a-7bfd1ab8972b"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 57 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}