{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wendianaxu/speech-emotion-recognition/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EwhgQXLPc-S1"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ3NhGjceXB4",
        "outputId": "c02d69ff-a350-46c7-e02e-d785597493c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'speech-emotion-recognition'...\n",
            "remote: Enumerating objects: 1510, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "^Cceiving objects:  55% (831/1510), 119.67 MiB | 3.26 MiB/s  \n",
            "fetch-pack: unexpected disconnect while reading sideband packet\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/wendianaxu/speech-emotion-recognition.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gLHkEMSf-za"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "GNAcBeb1eV-U",
        "outputId": "e1dc7796-07a3-4a10-b3f3-0909e2ec3bbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/d7/1kbvm4bx4213x2pp7svzg_p40000gp/T/ipykernel_37753/718035276.py:8: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sampling_rate = librosa.load(test_file, sr=sr, duration=None)\n",
            "/Applications/anaconda3/envs/ml-0451/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/speech-emotion-recognition/RAVDESS_data/Actor_01/03-01-01-01-01-01-01.wav'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m/Applications/anaconda3/envs/ml-0451/lib/python3.9/site-packages/librosa/core/audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m sf\u001b[39m.\u001b[39mSoundFileRuntimeError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    179\u001b[0m     \u001b[39m# If soundfile failed, try audioread instead\u001b[39;00m\n",
            "File \u001b[0;32m/Applications/anaconda3/envs/ml-0451/lib/python3.9/site-packages/librosa/core/audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[39m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     context \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39;49mSoundFile(path)\n\u001b[1;32m    211\u001b[0m \u001b[39mwith\u001b[39;00m context \u001b[39mas\u001b[39;00m sf_desc:\n",
            "File \u001b[0;32m/Applications/anaconda3/envs/ml-0451/lib/python3.9/site-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[1;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
            "File \u001b[0;32m/Applications/anaconda3/envs/ml-0451/lib/python3.9/site-packages/soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1216\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[1;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1218\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/content/speech-emotion-recognition/RAVDESS_data/Actor_01/03-01-01-01-01-01-01.wav': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m sr \u001b[39m=\u001b[39m \u001b[39m22050\u001b[39m \u001b[39m# sampling rate\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# visualize mfccs\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m audio, sampling_rate \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(test_file, sr\u001b[39m=\u001b[39;49msr, duration\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m      9\u001b[0m test_mfccs \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39mmfcc(y\u001b[39m=\u001b[39maudio, sr\u001b[39m=\u001b[39msr, n_mfcc\u001b[39m=\u001b[39mn_mfcc)\n\u001b[1;32m     11\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m5\u001b[39m))\n",
            "File \u001b[0;32m/Applications/anaconda3/envs/ml-0451/lib/python3.9/site-packages/librosa/core/audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[1;32m    181\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n",
            "File \u001b[0;32m/Applications/anaconda3/envs/ml-0451/lib/python3.9/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
            "File \u001b[0;32m/Applications/anaconda3/envs/ml-0451/lib/python3.9/site-packages/librosa/util/decorators.py:60\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     53\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mDeprecated as of librosa version \u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mIt will be removed in librosa version \u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,  \u001b[39m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[1;32m     59\u001b[0m )\n\u001b[0;32m---> 60\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/Applications/anaconda3/envs/ml-0451/lib/python3.9/site-packages/librosa/core/audio.py:241\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    238\u001b[0m     reader \u001b[39m=\u001b[39m path\n\u001b[1;32m    239\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[39m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     reader \u001b[39m=\u001b[39m audioread\u001b[39m.\u001b[39;49maudio_open(path)\n\u001b[1;32m    243\u001b[0m \u001b[39mwith\u001b[39;00m reader \u001b[39mas\u001b[39;00m input_file:\n\u001b[1;32m    244\u001b[0m     sr_native \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msamplerate\n",
            "File \u001b[0;32m/Applications/anaconda3/envs/ml-0451/lib/python3.9/site-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m BackendClass \u001b[39min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m BackendClass(path)\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
            "File \u001b[0;32m/Applications/anaconda3/envs/ml-0451/lib/python3.9/site-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39mopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/speech-emotion-recognition/RAVDESS_data/Actor_01/03-01-01-01-01-01-01.wav'"
          ]
        }
      ],
      "source": [
        "# test: load an audio file, extract mfccs, and visualize\n",
        "\n",
        "test_file = \"/content/speech-emotion-recognition/RAVDESS_data/Actor_01/03-01-01-01-01-01-01.wav\"\n",
        "n_mfcc = 13 # common choice\n",
        "sr = 22050 # sampling rate\n",
        "\n",
        "# visualize mfccs\n",
        "audio, sampling_rate = librosa.load(test_file, sr=sr, duration=None)\n",
        "test_mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "librosa.display.specshow(test_mfccs, \n",
        "                         x_axis=\"time\", \n",
        "                         sr=sr)\n",
        "plt.colorbar(format=\"%+2.f\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRo0EShAwUTP"
      },
      "outputs": [],
      "source": [
        "# function for loading an audio file\n",
        "data_path = \"/content/speech-emotion-recognition/RAVDESS_data/\"\n",
        "def load_file(path):\n",
        "  '''\n",
        "  Load one audio file and return an 1D array containing its mfccs averaged across time\n",
        "  '''\n",
        "  audio, sampling_rate = librosa.load(path, sr=sr, duration=None)\n",
        "  mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc) # extract MFCC matrix (cols = coefficients, rows = time)\n",
        "  features = np.mean(mfccs.T, axis=0)  # condense MFCC matrix into 1D array, averaging each coefficient across time\n",
        "  return features\n",
        "\n",
        "load_file(test_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Sp_TsXp52s",
        "outputId": "0d43a718-17e7-4236-87ae-d450ca3cc5f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X: (1440, 13)\n",
            "Shape of y: (1440,)\n"
          ]
        }
      ],
      "source": [
        "# function for preprocessing data\n",
        "def preprocess_data(path):\n",
        "  '''\n",
        "  Preprocess data in all folders within the dataset. \n",
        "  '''\n",
        "  X = []\n",
        "  y = []\n",
        "  for folder in os.listdir(path): # each folder = one actor\n",
        "      for file in os.listdir(os.path.join(path, folder)):\n",
        "          if file.endswith('.wav'):\n",
        "              emotion = file.split('-')[2] # get emotion label\n",
        "              if int(emotion) == 1:\n",
        "                  label = 'Neutral'\n",
        "              elif int(emotion) == 2:\n",
        "                  label = 'Calm'\n",
        "              elif int(emotion) == 3:\n",
        "                  label = 'Happy'\n",
        "              elif int(emotion) == 4:\n",
        "                  label = 'Sad'\n",
        "              elif int(emotion) == 5:\n",
        "                  label = 'Angry'\n",
        "              elif int(emotion) == 6:\n",
        "                  label = 'Fearful'\n",
        "              elif int(emotion) == 7:\n",
        "                  label = 'Disgust'\n",
        "              elif int(emotion) == 8:\n",
        "                  label = 'Surprised'\n",
        "              else:\n",
        "                  label = 'UNK'\n",
        "                  \n",
        "              file_path = os.path.join(path, folder, file)\n",
        "              features = load_file(file_path)\n",
        "              X.append(features)\n",
        "              y.append(label)\n",
        "  return np.array(X), np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU1ANDxI0dvC"
      },
      "outputs": [],
      "source": [
        "X, y = preprocess_data(data_path)\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVF4zKtRyG0U"
      },
      "outputs": [],
      "source": [
        "# train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YqnYpyEzQqX"
      },
      "outputs": [],
      "source": [
        "# inspect training data\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(X_train)\n",
        "df[\"label\"] = y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6wvvEuSTz8Ip",
        "outputId": "3e1061f0-80a1-41e7-eca2-d6e9dbc16c9c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-07cedaf7-6aad-41a1-bfa0-d312d83842b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-550.410706</td>\n",
              "      <td>65.115974</td>\n",
              "      <td>-2.515672</td>\n",
              "      <td>10.579401</td>\n",
              "      <td>13.258023</td>\n",
              "      <td>-1.245057</td>\n",
              "      <td>-1.945701</td>\n",
              "      <td>-4.436501</td>\n",
              "      <td>-6.648713</td>\n",
              "      <td>1.510386</td>\n",
              "      <td>-3.106131</td>\n",
              "      <td>-1.299466</td>\n",
              "      <td>-1.383189</td>\n",
              "      <td>Disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-449.255615</td>\n",
              "      <td>44.872730</td>\n",
              "      <td>-10.503033</td>\n",
              "      <td>4.327963</td>\n",
              "      <td>0.450368</td>\n",
              "      <td>-9.869686</td>\n",
              "      <td>1.562601</td>\n",
              "      <td>-2.047668</td>\n",
              "      <td>-8.703349</td>\n",
              "      <td>-0.105613</td>\n",
              "      <td>-4.688169</td>\n",
              "      <td>-0.417763</td>\n",
              "      <td>-2.481066</td>\n",
              "      <td>Angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-612.029053</td>\n",
              "      <td>68.371361</td>\n",
              "      <td>0.246289</td>\n",
              "      <td>11.889709</td>\n",
              "      <td>2.951385</td>\n",
              "      <td>-2.587057</td>\n",
              "      <td>-3.435470</td>\n",
              "      <td>-5.571574</td>\n",
              "      <td>-8.305638</td>\n",
              "      <td>-0.891437</td>\n",
              "      <td>2.646821</td>\n",
              "      <td>-3.349976</td>\n",
              "      <td>-1.120280</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-702.416138</td>\n",
              "      <td>76.888893</td>\n",
              "      <td>14.526176</td>\n",
              "      <td>24.579590</td>\n",
              "      <td>18.013536</td>\n",
              "      <td>1.145207</td>\n",
              "      <td>-0.617176</td>\n",
              "      <td>-0.802158</td>\n",
              "      <td>4.786394</td>\n",
              "      <td>0.019175</td>\n",
              "      <td>-0.432699</td>\n",
              "      <td>3.455811</td>\n",
              "      <td>0.539338</td>\n",
              "      <td>Surprised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-562.613281</td>\n",
              "      <td>49.607361</td>\n",
              "      <td>10.166953</td>\n",
              "      <td>15.956978</td>\n",
              "      <td>3.044477</td>\n",
              "      <td>3.288087</td>\n",
              "      <td>2.740135</td>\n",
              "      <td>-1.315588</td>\n",
              "      <td>-6.198551</td>\n",
              "      <td>-1.548467</td>\n",
              "      <td>6.139304</td>\n",
              "      <td>-1.397438</td>\n",
              "      <td>-0.779526</td>\n",
              "      <td>Disgust</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07cedaf7-6aad-41a1-bfa0-d312d83842b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07cedaf7-6aad-41a1-bfa0-d312d83842b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07cedaf7-6aad-41a1-bfa0-d312d83842b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0          1          2          3          4         5         6  \\\n",
              "0 -550.410706  65.115974  -2.515672  10.579401  13.258023 -1.245057 -1.945701   \n",
              "1 -449.255615  44.872730 -10.503033   4.327963   0.450368 -9.869686  1.562601   \n",
              "2 -612.029053  68.371361   0.246289  11.889709   2.951385 -2.587057 -3.435470   \n",
              "3 -702.416138  76.888893  14.526176  24.579590  18.013536  1.145207 -0.617176   \n",
              "4 -562.613281  49.607361  10.166953  15.956978   3.044477  3.288087  2.740135   \n",
              "\n",
              "          7         8         9        10        11        12      label  \n",
              "0 -4.436501 -6.648713  1.510386 -3.106131 -1.299466 -1.383189    Disgust  \n",
              "1 -2.047668 -8.703349 -0.105613 -4.688169 -0.417763 -2.481066      Angry  \n",
              "2 -5.571574 -8.305638 -0.891437  2.646821 -3.349976 -1.120280      Happy  \n",
              "3 -0.802158  4.786394  0.019175 -0.432699  3.455811  0.539338  Surprised  \n",
              "4 -1.315588 -6.198551 -1.548467  6.139304 -1.397438 -0.779526    Disgust  "
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A29ohJbTteeI"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "img = librosa.display.specshow(librosa.power_to_db(mfccs, ref=np.max),\n",
        "                               x_axis='time', y_axis='mel', fmax=8000,\n",
        "                               ax=ax[0])\n",
        "fig.colorbar(img, ax=[ax[0]])\n",
        "ax[0].set(title='Mel spectrogram')\n",
        "ax[0].label_outer()\n",
        "img = librosa.display.specshow(mfccs, x_axis='time', ax=ax[1])\n",
        "fig.colorbar(img, ax=[ax[1]])\n",
        "ax[1].set(title='MFCC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_by_statement(path, intensity = '01', repetition = '01', actor = '01'):\n",
        "  '''\n",
        "   \n",
        "  '''\n",
        "  X = []\n",
        "  y = []\n",
        "  color = ['red', 'blue', 'green', 'yellow', 'purple', 'orange', 'cyan', 'magenta']\n",
        "  x_values = range(13)\n",
        "  for file in os.listdir(os.path.join(path, 'Actor_'+ actor)):\n",
        "      if file.split('-')[3] == intensity and file.split('-')[5] == repetition:\n",
        "          emotion = file.split('-')[2] # get emotion label\n",
        "          if int(emotion) == 1:\n",
        "              mfcc = load_file(os.path.join(path, 'Actor_'+ actor, file))\n",
        "              plt.scatter(x_values, mfcc, color = color[0])\n",
        "          elif int(emotion) == 2:\n",
        "              mfcc = load_file(os.path.join(path, 'Actor_'+ actor, file))\n",
        "              plt.scatter(x_values, mfcc, color = color[1])\n",
        "          elif int(emotion) == 3:\n",
        "              mfcc = load_file(os.path.join(path, 'Actor_'+ actor, file))\n",
        "              plt.scatter(x_values, mfcc, color = color[2])\n",
        "          elif int(emotion) == 4:\n",
        "              mfcc = load_file(os.path.join(path, 'Actor_'+ actor, file))\n",
        "              plt.scatter(x_values, mfcc, color = color[3])\n",
        "          elif int(emotion) == 5:\n",
        "              mfcc = load_file(os.path.join(path, 'Actor_'+ actor, file))\n",
        "              plt.scatter(x_values, mfcc, color = color[4])\n",
        "          elif int(emotion) == 6:\n",
        "              mfcc = load_file(os.path.join(path, 'Actor_'+ actor, file))\n",
        "              plt.scatter(x_values, mfcc, color = color[5])\n",
        "          elif int(emotion) == 7:\n",
        "              mfcc = load_file(os.path.join(path, 'Actor_'+ actor, file))\n",
        "              plt.scatter(x_values, mfcc, color = color[6])\n",
        "          elif int(emotion) == 8:\n",
        "              mfcc = load_file(os.path.join(path, 'Actor_'+ actor, file))\n",
        "              plt.scatter(x_values, mfcc, color = color[7])\n",
        "  \n",
        "  plt.xlabel('Features')\n",
        "  plt.ylabel('MFCC Values')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data_path' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m visualize_by_statement(data_path)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_path' is not defined"
          ]
        }
      ],
      "source": [
        "visualize_by_statement(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sort emotions into bins\n",
        "Neutral = []\n",
        "Calm = []\n",
        "Happy = []\n",
        "Sad = []\n",
        "Angry = []\n",
        "Fearful = []\n",
        "Disgust = []\n",
        "Surprised = []\n",
        "UNK = []\n",
        "\n",
        "def emo_classification(X, y):\n",
        "  for i in range(X.shape[0]):\n",
        "    if y[i] == 'Neutral':\n",
        "      Neutral.append(X[i])\n",
        "    elif y[i] == 'Calm':\n",
        "      Calm.append(X[i])\n",
        "    elif y[i] == 'Happy':\n",
        "      Happy.append(X[i])\n",
        "    elif y[i] == 'Sad':\n",
        "      Sad.append(X[i])\n",
        "    elif y[i] == 'Angry':\n",
        "      Angry.append(X[i])\n",
        "    elif y[i] == 'Fearful':\n",
        "      Fearful.append(X[i])\n",
        "    elif y[i] == 'Disgust':\n",
        "      Disgust.append(X[i])\n",
        "    elif y[i] == 'Surprised':\n",
        "      Surprised.append(X[i])\n",
        "    elif y[i] == 'UNK':\n",
        "      UNK.append(X[i])\n",
        "\n",
        "emo_classification(X, y)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
